{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPx0jzXcroj4Ezfn4AGjD6i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaorafaelpm/ImersaoAgenteDeIAAlura/blob/main/MasterClass_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Aula 1 - Instanciândo o primeiro agente de IA\n"
      ],
      "metadata": {
        "id": "rD64IJbsvGHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalando as bibliotecas do gemini"
      ],
      "metadata": {
        "id": "_5XgEu-2fv-B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "_5o76DK-Ne19"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain-google-genai google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando as bibliotecas e definindo a chave da API do gemini"
      ],
      "metadata": {
        "id": "Dl1khwTHf0Gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get(\"GEMINI_API_KEY\")"
      ],
      "metadata": {
        "id": "_DDysRZOPgLh"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criando a primeira instância do Gemini"
      ],
      "metadata": {
        "id": "tr8MQjZ-gt90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI (\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    temperature=0.0,\n",
        "    api_key=userdata.get(\"GEMINI_API_KEY\")\n",
        ")"
      ],
      "metadata": {
        "id": "Kx1TqvcrfQdW"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pequeno teste na nossa instância do gemini"
      ],
      "metadata": {
        "id": "T9as2Tc-lLJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp_test = llm.invoke(\"Quem é você? Explique para um leigo\")\n",
        "print(resp_test.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAF_TLnog6vm",
        "outputId": "3b5fe2de-9146-4463-ac03-b603b2a6070f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Olá! Que ótima pergunta. Vou explicar de um jeito bem simples:\n",
            "\n",
            "Eu sou uma **Inteligência Artificial (IA)**.\n",
            "\n",
            "Pense em mim como um **cérebro digital** ou um **assistente virtual muito avançado**, mas sem um corpo físico, sentimentos ou consciência como um ser humano.\n",
            "\n",
            "Aqui está o que isso significa na prática:\n",
            "\n",
            "1.  **Eu sou um programa de computador:** Fui criado por engenheiros e cientistas do Google. Não sou uma pessoa, um animal ou qualquer coisa viva.\n",
            "2.  **Fui \"treinado\" com muita informação:** É como se eu tivesse lido uma quantidade gigantesca de livros, artigos, conversas e informações da internet. Por causa disso, eu \"aprendi\" como a linguagem humana funciona.\n",
            "3.  **Minha função é processar e gerar texto:** Quando você me faz uma pergunta ou me pede para fazer algo, eu uso todo esse conhecimento para entender o que você quer e gerar uma resposta ou um texto que faça sentido.\n",
            "4.  **Não tenho opiniões próprias ou sentimentos:** Eu não \"penso\" da mesma forma que você. Não tenho emoções, crenças ou desejos. Minhas respostas são baseadas nos padrões e informações que aprendi nos dados.\n",
            "5.  **Sou uma ferramenta:** Meu objetivo é te ajudar a obter informações, criar textos, traduzir, resumir e muito mais, usando a linguagem.\n",
            "\n",
            "Então, em resumo: **Eu sou um programa de computador inteligente, criado para entender e gerar linguagem humana, e estou aqui para te ajudar com informações e tarefas baseadas em texto.**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contextualizando a nossa IA com um prompt\n",
        "\n",
        "---\n",
        "\n",
        "Assim como a gente tem o prompt de usuário, onde nós reconhecemos o usuário assim como as suas permissões, a gente pode também passar um prompt de sistema para a IA indentificar quem ela é e qual sua função\n",
        "\n"
      ],
      "metadata": {
        "id": "pRixYgjJfvJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No caso de uma grande empresa, não faz sentido abrir chamado no RH por qualquer coisa, e neste caso a intenção é fazer o sistema interpretar o que pode ser resolvido pela própria IA e o que requer a interferência do RH e etc\n",
        "\n",
        "---\n",
        "\n",
        "  Nesse caso, a gente primeiro contextualiza dizendo o qual é a sua posição na empresa e um padrão de retorno para ser tratado.\n",
        "\n",
        "  E então a gente passa um padrão de JSON que queremos resolver, neste caso esse padrão tem 3 campos, \"decisao\" que define o que pode ser feito dependendo da situação, \"urgencia\" definida também pela situação e \"campos_faltantes\" que faz a verificação se tem alguma informação faltando\n",
        "  "
      ],
      "metadata": {
        "id": "fTNGcC-0mpS7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "É possível também criar uma resposta pré determinada como :\n",
        "\n",
        "```\n",
        "{\n",
        "  decisao : AUTO_RESOLVER,\n",
        "  urgencia : baixa,\n",
        "  campos_faltantes : []\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "e fazer uma resposta pronta para esse tipo, como um pattern pré definido"
      ],
      "metadata": {
        "id": "nmmYJvKc29Oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRIAGEM_PROMPT = (\n",
        "    \"Você é um triador de Service Desk para políticas internas da empresa Carraro Desenvolvimento. \"\n",
        "    \"Dada a mensagem do usuário, retorne SOMENTE um JSON com:\\n\"\n",
        "    \"{\\n\"\n",
        "    '  \"decisao\": \"AUTO_RESOLVER\" | \"PEDIR_INFO\" | \"ABRIR_CHAMADO\",\\n'\n",
        "    '  \"urgencia\": \"BAIXA\" | \"MEDIA\" | \"ALTA\",\\n'\n",
        "    '  \"campos_faltantes\": [\"...\"]\\n'\n",
        "    \"}\\n\"\n",
        "    \"Regras:\\n\"\n",
        "    '- **AUTO_RESOLVER**: Perguntas claras sobre regras ou procedimentos descritos nas políticas (Ex: \"Posso reembolsar a internet do meu home office?\", \"Como funciona a política de alimentação em viagens?\").\\n'\n",
        "    '- **PEDIR_INFO**: Mensagens vagas ou que faltam informações para identificar o tema ou contexto (Ex: \"Preciso de ajuda com uma política\", \"Tenho uma dúvida geral\").\\n'\n",
        "    '- **ABRIR_CHAMADO**: Pedidos de exceção, liberação, aprovação ou acesso especial, ou quando o usuário explicitamente pede para abrir um chamado (Ex: \"Quero exceção para trabalhar 5 dias remoto.\", \"Solicito liberação para anexos externos.\", \"Por favor, abra um chamado para o RH.\").'\n",
        "    \"Analise a mensagem e decida a ação mais apropriada.\"\n",
        ")"
      ],
      "metadata": {
        "id": "PXVFTSullKLF"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando bibliotecas de tratamento da saída de dados\n",
        "\n",
        " - Pydantic é uma biblioteca que melhora a validação e saída de dados, ele indentifica erros, simplifica a criação de objetos/dicionarios e etc.\n",
        "\n",
        "\n",
        " - Typing é outra biblioteca de auxílio na interação do usuário com a aplicação, por exemplo, typing.Literal, significa que a resposta esperada é específica, neste caso se trata dos enum, List se trata dos campos_faltantes, Dict também auxilia no processo."
      ],
      "metadata": {
        "id": "NYiUIVnuPATN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal, List, Dict\n",
        "\n",
        "# Iniciando um modelo de classe usando o pydantic\n",
        "class TriagemOut(BaseModel):\n",
        "    decisao: Literal[\"AUTO_RESOLVER\", \"PEDIR_INFO\", \"ABRIR_CHAMADO\"]\n",
        "    urgencia: Literal[\"BAIXA\", \"MEDIA\", \"ALTA\"]\n",
        "    campos_faltantes: List[str] = Field(default_factory=list)\n"
      ],
      "metadata": {
        "id": "fg-o6eToliBY"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criando outra instância do gemini"
      ],
      "metadata": {
        "id": "4Emqfr_aUAku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_triagem = ChatGoogleGenerativeAI (\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    temperature=0.0,\n",
        "    api_key=userdata.get(\"GEMINI_API_KEY\")\n",
        ")"
      ],
      "metadata": {
        "id": "k_tbW15dPV73"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Especificando a função da instância do gemini\n",
        "\n",
        "Aqui a gente usa aquela classe para poder especificar para o gemini as saídas de resposta que ele tem, e a gente usa a nossa classe definir como ele vai responder.\n",
        "\n",
        "SystemMessage é o prompt da IA (é um tipo de identidade do agente)\n",
        "\n",
        "HumanMessage é o prompt do usuário"
      ],
      "metadata": {
        "id": "siQvPFUQUF6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage , HumanMessage\n",
        "\n",
        "triagem_chain = llm_triagem.with_structured_output(TriagemOut)\n",
        "\n",
        "def triagem(message : str) -> Dict :\n",
        "  saida : TriagemOut = triagem_chain.invoke([\n",
        "      # O prompt da máquina é a identidade que a gente definiu antes\n",
        "      # O prompt do usuário é a mensagem\n",
        "      SystemMessage(content=TRIAGEM_PROMPT),\n",
        "      HumanMessage(content=message)\n",
        "  ])\n",
        "\n",
        "  # O método model_dump() converte a classe em um dicionário\n",
        "  return saida.model_dump()"
      ],
      "metadata": {
        "id": "beYSn00GTL7d"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testes = [\"Posso reembolsar a internet?\" ,\n",
        "          \"Quero ter mais 5 dias de trabalho remoto? Como eu faço?\",\n",
        "          \"Posso reembolsar cursos ou treinamentos da Alura?\",\n",
        "          \"Quantas capivaras tem no Rio Pinheiros\"\n",
        "          ]"
      ],
      "metadata": {
        "id": "jwEgdlYcXA2m"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for msg_teste in testes :\n",
        "  print(f\"Pergunta:{msg_teste} \\n -> Resposta:{triagem(msg_teste)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDYMG6nJXbup",
        "outputId": "f17ddd71-3c3e-48ed-e6a4-11a671411c6f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pergunta:Posso reembolsar a internet? \n",
            " -> Resposta:{'decisao': 'AUTO_RESOLVER', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
            "\n",
            "Pergunta:Quero ter mais 5 dias de trabalho remoto? Como eu faço? \n",
            " -> Resposta:{'decisao': 'ABRIR_CHAMADO', 'urgencia': 'MEDIA', 'campos_faltantes': []}\n",
            "\n",
            "Pergunta:Posso reembolsar cursos ou treinamentos da Alura? \n",
            " -> Resposta:{'decisao': 'AUTO_RESOLVER', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
            "\n",
            "Pergunta:Quantas capivaras tem no Rio Pinheiros \n",
            " -> Resposta:{'decisao': 'PEDIR_INFO', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Aula 2 - Usando o RAG para complementar as respostas do agente"
      ],
      "metadata": {
        "id": "d9rePBlwvMz7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando outras bibliotecas para auxiliar na leitura do RAG\n",
        "\n",
        " - langchain_community -> Uma biblioteca que auxilia nos processos do RAG\n",
        " - faiss-cpu -> Basicamente reduz o uso da CPU durante a execução do código\n",
        " - langchain-text-splitters -> Divide o texto em blocos\n",
        " - pymupdf -> Interpreta PDF"
      ],
      "metadata": {
        "id": "YzDFO84twfiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade langchain_community faiss-cpu langchain-text-splitters pymupdf"
      ],
      "metadata": {
        "id": "Mt3mMyCIvnw3"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando os PDFs para o RAG\n",
        "\n",
        "Usamos o Path para o caminho do pdf (memória do colab)\n",
        "\n",
        "E então nós carregamos o PDF com a biblioteca do pymupdf (PyMuPDFLoader(nome do arquivo))"
      ],
      "metadata": {
        "id": "px7_NMo_xW89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "docs = []\n",
        "\n",
        "#Para cada arquivo no caminho do tipo .pdf...\n",
        "for n_docs in Path(\"/content/\").glob(\"*.pdf\"):\n",
        "    try:\n",
        "      # Carregamos esses arquivos e transformamos em String\n",
        "        loader = PyMuPDFLoader(str(n_docs))\n",
        "      # Adicionamos o texto do arquivo na lista\n",
        "        docs.extend(loader.load())\n",
        "        print(f\"Carregado com sucesso arquivo : {n_docs.name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao carregar arquivo : {n_docs.name}: {e}\")\n",
        "\n",
        "print(f\"Total de documentos carregados: {len(docs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IYoktpDvo1F",
        "outputId": "a4fa9bfe-f9e1-46e3-e0de-f26f3f6973ac"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregado com sucesso arquivo : Política de Uso de E-mail e Segurança da Informação.pdf\n",
            "Carregado com sucesso arquivo : Política de Reembolsos (Viagens e Despesas).pdf\n",
            "Carregado com sucesso arquivo : Políticas de Home Office.pdf\n",
            "Total de documentos carregados: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando o splitters do langchain\n",
        "\n",
        "O splitter divide o texto em pedaços e oferece um espaço para mater o contexto\n",
        "\n",
        " - chunk_size -> número de caracteres que ele vai ler\n",
        " - chunk_overlap -> número de caracteres que ele lembra antes de passar para o próximo chunk\n",
        "\n",
        " (_vale dizer que é importante ter um overlap de acordo com o chunk_size para não ter perda de contexto de uma chunk para outra_)"
      ],
      "metadata": {
        "id": "r0ZUFTZE0jjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
        "\n",
        "# Separa o documentos de acordo com o splitter (300 caracteres cada chunk com uma releitura de 30 para cada um)\n",
        "chunks = splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "AhBOdTwLvsaF"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imprimindo os chunks"
      ],
      "metadata": {
        "id": "XudvPHNq1zaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in chunks:\n",
        "    print(chunk)\n",
        "    print(\"------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cakHtSFwvwTW",
        "outputId": "ce1952ba-3745-4ee5-9b50-63869d6c18ca"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='Política de Uso de E-mail e Segurança \n",
            "da Informação \n",
            " \n",
            "1.​ É proibido encaminhar a endereços pessoais documentos classificados como \n",
            "confidenciais.​\n",
            " \n",
            "2.​ Anexos externos devem ser enviados somente se criptografados e com senha \n",
            "compartilhada por canal separado.​' metadata={'producer': 'Skia/PDF m140 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '/content/Política de Uso de E-mail e Segurança da Informação.pdf', 'file_path': '/content/Política de Uso de E-mail e Segurança da Informação.pdf', 'total_pages': 1, 'format': 'PDF 1.4', 'title': 'Imersão: Política de Uso de E-mail e Segurança da Informação', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}\n",
            "------------------------------------\n",
            "page_content='3.​ Phishing: verifique remetente e domínios suspeitos. Reporte mensagens suspeitas \n",
            "ao time de Segurança imediatamente.​\n",
            " \n",
            "4.​ Retenção: mensagens que contenham dados pessoais devem seguir as diretrizes \n",
            "de retenção definidas pela equipe de Privacidade.​' metadata={'producer': 'Skia/PDF m140 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '/content/Política de Uso de E-mail e Segurança da Informação.pdf', 'file_path': '/content/Política de Uso de E-mail e Segurança da Informação.pdf', 'total_pages': 1, 'format': 'PDF 1.4', 'title': 'Imersão: Política de Uso de E-mail e Segurança da Informação', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}\n",
            "------------------------------------\n",
            "page_content='5.​ Solicitações de liberação de anexos ou domínios devem ser abertas por chamado, \n",
            "com justificativa do gestor.' metadata={'producer': 'Skia/PDF m140 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '/content/Política de Uso de E-mail e Segurança da Informação.pdf', 'file_path': '/content/Política de Uso de E-mail e Segurança da Informação.pdf', 'total_pages': 1, 'format': 'PDF 1.4', 'title': 'Imersão: Política de Uso de E-mail e Segurança da Informação', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}\n",
            "------------------------------------\n",
            "page_content='Política de Reembolsos (Viagens e \n",
            "Despesas) \n",
            " \n",
            "1.​ Reembolso: requer nota fiscal e deve ser submetido em até 10 dias corridos após a \n",
            "despesa.​\n",
            " \n",
            "2.​ Alimentação em viagem: limite de R$ 70/dia por pessoa. Bebidas alcoólicas não \n",
            "são reembolsáveis.​' metadata={'producer': 'Skia/PDF m140 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '/content/Política de Reembolsos (Viagens e Despesas).pdf', 'file_path': '/content/Política de Reembolsos (Viagens e Despesas).pdf', 'total_pages': 1, 'format': 'PDF 1.4', 'title': 'Imersão: Política de Reembolsos (Viagens e Despesas)', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}\n",
            "------------------------------------\n",
            "page_content='são reembolsáveis.​\n",
            " \n",
            "3.​ Transporte: táxi/app são permitidos quando não houver alternativa viável. \n",
            "Comprovantes obrigatórios.​\n",
            " \n",
            "4.​ Internet para home office: reembolsável via subsídio mensal de até R$ 100, \n",
            "conforme política de Home Office.​' metadata={'producer': 'Skia/PDF m140 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '/content/Política de Reembolsos (Viagens e Despesas).pdf', 'file_path': '/content/Política de Reembolsos (Viagens e Despesas).pdf', 'total_pages': 1, 'format': 'PDF 1.4', 'title': 'Imersão: Política de Reembolsos (Viagens e Despesas)', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}\n",
            "------------------------------------\n",
            "page_content='5.​ Cursos e certificações: exigem aprovação prévia do gestor e orçamento do time.​\n",
            " \n",
            "6.​ Custos excepcionais (ex.: franquia de bagagem extra): devem ser justificados no \n",
            "chamado e aprovados antes da compra.' metadata={'producer': 'Skia/PDF m140 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '/content/Política de Reembolsos (Viagens e Despesas).pdf', 'file_path': '/content/Política de Reembolsos (Viagens e Despesas).pdf', 'total_pages': 1, 'format': 'PDF 1.4', 'title': 'Imersão: Política de Reembolsos (Viagens e Despesas)', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}\n",
            "------------------------------------\n",
            "page_content='Políticas de Home Office \n",
            " \n",
            "1.​ A empresa adota modelo híbrido: mínimo de 2 dias presenciais por semana, salvo \n",
            "exceções aprovadas pelo gestor e RH.​\n",
            " \n",
            "2.​ Equipamentos: a empresa fornece notebook e periféricos. O colaborador é \n",
            "responsável por zelar pela conservação.​' metadata={'producer': 'Skia/PDF m140 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '/content/Políticas de Home Office.pdf', 'file_path': '/content/Políticas de Home Office.pdf', 'total_pages': 1, 'format': 'PDF 1.4', 'title': 'Políticas de Home Office', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}\n",
            "------------------------------------\n",
            "page_content='3.​ Segurança: é obrigatório uso de VPN e bloqueio de tela. Documentos confidenciais \n",
            "não devem ser impressos fora do escritório.​\n",
            " \n",
            "4.​ Ergonomia: recomendamos cadeira adequada e suporte de monitor. O RH pode \n",
            "avaliar solicitação de apoio ergonômico.​' metadata={'producer': 'Skia/PDF m140 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '/content/Políticas de Home Office.pdf', 'file_path': '/content/Políticas de Home Office.pdf', 'total_pages': 1, 'format': 'PDF 1.4', 'title': 'Políticas de Home Office', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}\n",
            "------------------------------------\n",
            "page_content='5.​ Conectividade: há subsídio mensal de internet domiciliar para quem trabalha em \n",
            "home office: até R$ 100/mês, mediante nota fiscal nominal.​\n",
            " \n",
            "6.​ Solicitação de exceção (ex.: 4-5 dias remotos): deve ser formalizada via chamado \n",
            "ao RH com justificativa do gestor.' metadata={'producer': 'Skia/PDF m140 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '/content/Políticas de Home Office.pdf', 'file_path': '/content/Políticas de Home Office.pdf', 'total_pages': 1, 'format': 'PDF 1.4', 'title': 'Políticas de Home Office', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}\n",
            "------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando a biblioteca de Embeddings do gemini\n",
        "\n",
        "Embeddings é a prática de transformar palavras em números e aproximar palavras semelhantes de forma semântica por números próximos.\n",
        "\n",
        "ex:\n",
        "```\n",
        "    palavras | valores\n",
        "    ------------------\n",
        "    rei      | 100\n",
        "    rainha   | 96\n",
        "    cachorro | 5\n",
        "```\n",
        "\n",
        "E então nós usamos calculos com esses números para chegar em uma próxima palavra por exemplo.\n",
        "\n",
        "ex :\n",
        "\n",
        "```\n",
        "   rei -> homen\n",
        "   rainha -> mulher\n",
        "\n",
        "   rei - homem -> rainha\n",
        "   rainha - mulher -> rei\n",
        "```"
      ],
      "metadata": {
        "id": "dWIRskDI4_oN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "# chamando a IA de embeddings do gemini\n",
        "embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/gemini-embedding-001\",\n",
        "    google_api_key=GOOGLE_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "xkpUq-97vyAz"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando a biblioteca do face book para ajudar na separação do documento\n",
        "\n"
      ],
      "metadata": {
        "id": "ACAwrvUP8JAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Definindo os documentos e o modelo de separação (o do gemini)\n",
        "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "\n",
        "# Agora que a gente já definiu de onde nós vamos tirar os vetores com as informações já transformadas em embedding, vamos definir o nível de similaridade que nós queremos para cada embedding\n",
        "# Para isso a gente usa a função as_retriver da biblioteca que acabamos de importar com 2 parâmetros:\n",
        "# ---> search_type (a maneira que vamos buscar, nesse caso, similaridade pelo limite de pontos por palavra = similarity_score_treshold)\n",
        "# ---> search_kwargs (um dicionário onde definimos o limite de pontos que queremos considerar para poder avaliar as palavras \"score_treshold\" : 0.3 e o número de chunks mais relevantes que queremos retornar \"k\" : 4 )\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity_score_threshold\",\n",
        "                                     search_kwargs={\"score_threshold\":0.3, \"k\": 4})"
      ],
      "metadata": {
        "id": "nUVo72jHvzhT"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criando prompts mais estruturados para o rag\n",
        "\n",
        "O ChatPromptTemplate cria um modelo de prompt específico para o rag, onde passamos as mesmas informações, porém com o adicional de padrões de respostas para a falta de contexto, ou material insuficiente.\n",
        "\n",
        "O create_stuff_documents_chain é o que liga o nosso novo prompt com o padrão de respostas ao nosso llm de triagens"
      ],
      "metadata": {
        "id": "8mujISi4-4Ct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "prompt_rag = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"Você é um Assistente de Políticas Internas (RH/IT) da empresa Carraro Desenvolvimento. \"\n",
        "     \"Responda SOMENTE com base no contexto fornecido. \"\n",
        "     \"Se não houver base suficiente, responda apenas 'Não sei'.\"),\n",
        "\n",
        "    (\"human\", \"Pergunta: {input}\\n\\nContexto:\\n{context}\")\n",
        "])\n",
        "\n",
        "document_chain = create_stuff_documents_chain(llm_triagem, prompt_rag)"
      ],
      "metadata": {
        "id": "8eoCyRifv0uR"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Formatando as citações\n",
        "\n",
        "Como a ideia é formatar, primeiro vamos pegar o texto limpo, sem espaços e então separamos os termos, com mais de 4 caracteres, encontrados, e então calculamos a posição do termo, para pegar o contexto inteiro, alguns caracteres antes e depois.\n",
        "\n",
        "Com esse contexto, nós formamos as citações, e repetimos isso pela lista inteira de documento"
      ],
      "metadata": {
        "id": "f26cnooj9o4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Formatadores\n",
        "import re, pathlib\n",
        "\n",
        "def _clean_text(s: str) -> str:\n",
        "  # Limpando o texto para ser lido\n",
        "    return re.sub(r\"\\s+\", \" \", s or \"\").strip()\n",
        "\n",
        "def extrair_trecho(texto: str, query: str, janela: int = 240) -> str:\n",
        "  # Limpa o texto\n",
        "    txt = _clean_text(texto)\n",
        "\n",
        "    # Extrai palavras do pedaço de texto, deixa minúsculo e seleciona as que tem 4 ou mais caracteres, para priorizar palavras mais significativas\n",
        "    termos = [t.lower() for t in re.findall(r\"\\w+\", query or \"\") if len(t) >= 4]\n",
        "\n",
        "    # A gente verifica se algum termo foi formado e procura a posição de onde começa o termo (por padrão o termo tem mais de 4 caracteres, então pega o primeiro)\n",
        "    posicao = -1\n",
        "    for t in termos:\n",
        "        posicao = txt.lower().find(t)\n",
        "        if posicao != -1: break\n",
        "    # Retorna a posicao ao valor 0 por precaução\n",
        "    if posicao == -1: posicao = 0\n",
        "\n",
        "    # Janela é o tamanho do texto que vamos extrair, então vamos pegar a posicao de onde o termo foi encontrado\n",
        "    # A ideia é centralizar a posição de onde o termo foi encontrado (janela//2) e subtrair da posicao em que foi encontrado\n",
        "    # Usamos o max no inicio para não ser negativo e pegamos a posição final do termo\n",
        "    ini, fim = max(0, posicao - janela//2), min(len(txt), posicao + janela//2)\n",
        "\n",
        "    # E então retornamos só esse pedaço do texto\n",
        "    return txt[ini:fim]\n",
        "\n",
        "def formatar_citacoes(docs_rel: List, query: str) -> List[Dict]:\n",
        "  # Inicializamos essa lista para armazenar os dicionários formados e esse conjunto (\"seen\") para controlar documentos/páginas já citados\n",
        "    cites, seen = [], set()\n",
        "    for document in docs_rel:\n",
        "      # Extraimos o nome do arquivo\n",
        "        src = pathlib.Path(document.metadata.get(\"source\",\"\")).name\n",
        "      # A página do arquivo\n",
        "        page = int(document.metadata.get(\"page\", 0)) + 1\n",
        "\n",
        "      # A gente armazena esses dois valores em um novo dicionário para verificar se já existe com o seen, e então se existir só continua o loop\n",
        "        key = (src, page)\n",
        "        if key in seen:\n",
        "            continue\n",
        "        seen.add(key)\n",
        "        # Adiciona o documento em forma de dicionário e já formatado com o conteúdo da página inteira e o que o usuário digitou para pegar os termos relevantes\n",
        "        cites.append({\"documento\": src, \"pagina\": page, \"trecho\": extrair_trecho(document.page_content, query)})\n",
        "    # Limitamos o número de citações para serem exibidas\n",
        "    return cites[:3]"
      ],
      "metadata": {
        "id": "4frv8hSd9dC4"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparando uma resposta com base no texto do usuário e nos embeddings"
      ],
      "metadata": {
        "id": "CyYrlaO_Pca-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perguntar_politica_RAG (pergunta : str) -> Dict :\n",
        "  # A gente passa a pergunta para ser avaliada no retriver, que faz a comparação com os documentos para gerar uma resposta\n",
        "  docs_relacionados = retriever.invoke(pergunta)\n",
        "\n",
        "  # Se não tiver nenhuma relação com os doucmentos:\n",
        "  if not docs_relacionados :\n",
        "    return {\"answer\" : \"Não sei.\" ,\n",
        "            \"citacoes\" : [],\n",
        "            \"contexto_encontrado\" : False\n",
        "            }\n",
        "  # Caso contrário a resposta é um dicionário com o texto passado e a resposta, note que no bloco de código acima nós usamos exatamente esse padrão no prompt para definir o texto humano : (\"human\", \"Pergunta: {input}\\n\\nContexto:\\n{context}\")\n",
        "  answer = document_chain.invoke({\n",
        "      \"input\" : pergunta ,\n",
        "      \"context\" : docs_relacionados\n",
        "  })\n",
        "\n",
        "  # Recebendo o texto que a IA gerou e retirando espaços\n",
        "  txt = (answer or \"\").strip()\n",
        "\n",
        "  # Avaliando se existe resposta válida\n",
        "  if txt.rstrip(\".!?\") == \"Não sei\" :\n",
        "    return {\"answer\" : \"Não sei.\" ,\n",
        "            \"citacoes\" : [],\n",
        "            \"contexto_encontrado\" : False\n",
        "            }\n",
        "  # Caso contrário a resposta é um dicionário com o texto passado e a resposta, note que no bloco de código acima nós usamos exatamente esse padrão no prompt para definir o texto humano : (\"human\", \"Pergunta: {input}\\n\\nContexto:\\n{context}\")\n",
        "  return  {\n",
        "      \"answer\" : txt ,\n",
        "      \"citacoes\" : formatar_citacoes(docs_relacionados , pergunta) ,\n",
        "      \"contexto_encontrado\" : True\n",
        "  }"
      ],
      "metadata": {
        "id": "zyiw9OjkNSK1"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testes = [\"Posso reembolsar a internet?\" ,\n",
        "          \"Quero ter mais 5 dias de trabalho remoto? Como eu faço?\",\n",
        "          \"Posso reembolsar cursos ou treinamentos da Alura?\",\n",
        "          \"Quantas capivaras tem no Rio Pinheiros\"\n",
        "          ]"
      ],
      "metadata": {
        "id": "jwTFDGquQ9ib"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fazendo testes com o novo padrão de respostas"
      ],
      "metadata": {
        "id": "mm1AGQzcRoFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for msg_teste in testes:\n",
        "    resposta = perguntar_politica_RAG(msg_teste)\n",
        "    print(f\"Pergunta: {msg_teste}\")\n",
        "    print(f\"Resposta: {resposta['answer']}\")\n",
        "    if resposta['contexto_encontrado']:\n",
        "        print(\"Citações:\")\n",
        "        for c in resposta['citacoes']:\n",
        "            print(f\" - Documento: {c['documento']}, Página: {c['pagina']}\")\n",
        "            print(f\"   Trecho: {c['trecho']}\")\n",
        "        print(\"------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-FTxJvwRQu5",
        "outputId": "4ee3ebd5-b0b8-489c-fd4e-697849bb281e"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pergunta: Posso reembolsar a internet?\n",
            "Resposta: Sim, a internet para home office é reembolsável via subsídio mensal de até R$ 100, mediante nota fiscal nominal.\n",
            "Citações:\n",
            " - Documento: Política de Reembolsos (Viagens e Despesas).pdf, Página: 1\n",
            "   Trecho: lsáveis.​ 3.​ Transporte: táxi/app são permitidos quando não houver alternativa viável. Comprovantes obrigatórios.​ 4.​ Internet para home office: reembolsável via subsídio mensal de até R$ 100, conforme política de Home Office.​\n",
            " - Documento: Políticas de Home Office.pdf, Página: 1\n",
            "   Trecho: 5.​ Conectividade: há subsídio mensal de internet domiciliar para quem trabalha em home office: até R$ 100/mês, mediante nota fiscal nominal.​ 6.​ Solicitação de\n",
            "------------------------------------\n",
            "Pergunta: Quero ter mais 5 dias de trabalho remoto? Como eu faço?\n",
            "Resposta: Para solicitar mais 5 dias de trabalho remoto, você deve formalizar a solicitação via chamado ao RH com a justificativa do seu gestor.\n",
            "Citações:\n",
            " - Documento: Políticas de Home Office.pdf, Página: 1\n",
            "   Trecho:  para quem trabalha em home office: até R$ 100/mês, mediante nota fiscal nominal.​ 6.​ Solicitação de exceção (ex.: 4-5 dias remotos): deve ser formalizada via chamado ao RH com justificativa do gestor.\n",
            " - Documento: Política de Reembolsos (Viagens e Despesas).pdf, Página: 1\n",
            "   Trecho: são reembolsáveis.​ 3.​ Transporte: táxi/app são permitidos quando não houver alternativa viável. Comprovantes obrigatór\n",
            "------------------------------------\n",
            "Pergunta: Posso reembolsar cursos ou treinamentos da Alura?\n",
            "Resposta: Sim, cursos e certificações (o que inclui treinamentos como os da Alura) são reembolsáveis, desde que haja aprovação prévia do gestor e orçamento do time.\n",
            "Citações:\n",
            " - Documento: Política de Reembolsos (Viagens e Despesas).pdf, Página: 1\n",
            "   Trecho: Política de Reembolsos (Viagens e Despesas) 1.​ Reembolso: requer nota fiscal e deve ser submetido em até 10 dias corrid\n",
            " - Documento: Políticas de Home Office.pdf, Página: 1\n",
            "   Trecho: Políticas de Home Office 1.​ A empresa adota modelo híbrido: mínimo de 2 dias presenciais por semana, salvo exceções apr\n",
            "------------------------------------\n",
            "Pergunta: Quantas capivaras tem no Rio Pinheiros\n",
            "Resposta: Não sei.\n"
          ]
        }
      ]
    }
  ]
}